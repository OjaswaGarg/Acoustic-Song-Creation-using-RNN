{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Pierian-Data-Logo.PNG\">\n",
    "<br>\n",
    "<strong><center>Copyright 2019. Created by Jose Marcial Portilla.</center></strong>\n",
    "\n",
    "# RNN for Text Generation\n",
    "\n",
    "## Generating Text (encoded variables)\n",
    "\n",
    "We saw how to generate continuous values, now let's see how to generalize this to generate categorical sequences (such as words or letters).\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/Ed_Sheeran.txt','r',encoding='utf8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Perfect\\nI found a love for me\\nOh darling, just dive right in and follow my lead\\nWell, I found a girl, beautiful and sweet\\nOh, I never knew you were the someone waiting for me\\n'Cause we were just kids when we fell in love\\nNot knowing what it was\\nI will not give you up this time\\nBut darling, just kiss me slow, your heart is all I own\\nAnd in your eyes, you're holding mine\\nBaby, I'm dancing in the dark with you between my arms\\nBarefoot on the grass, listening to our favourite song\\nWhen you said you looked a mess, I whispered underneath my breath\\nBut you heard it, darling, you look perfect tonight\\nWell I found a woman, stronger than anyone I know\\nShe shares my dreams, I hope that someday I'll share her home\\nI found a love, to carry more than just my secrets\\nTo carry love, to carry children of our own\\nWe are still kids, but we're so in love\\nFighting against all odds\\nI know we'll be alright this time\\nDarling, just hold my hand\\nBe my girl, I'll be your man\\nI see my future in your eyes\\nBaby, I'\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfect\n",
      "I found a love for me\n",
      "Oh darling, just dive right in and follow my lead\n",
      "Well, I found a girl, beautiful and sweet\n",
      "Oh, I never knew you were the someone waiting for me\n",
      "'Cause we were just kids when we fell in love\n",
      "Not knowing what it was\n",
      "I will not give you up this time\n",
      "But darling, just kiss me slow, your heart is all I own\n",
      "And in your eyes, you're holding mine\n",
      "Baby, I'm dancing in the dark with you between my arms\n",
      "Barefoot on the grass, listening to our favourite song\n",
      "When you said you looked a mess, I whispered underneath my breath\n",
      "But you heard it, darling, you look perfect tonight\n",
      "Well I found a woman, stronger than anyone I know\n",
      "She shares my dreams, I hope that someday I'll share her home\n",
      "I found a love, to carry more than just my secrets\n",
      "To carry love, to carry children of our own\n",
      "We are still kids, but we're so in love\n",
      "Fighting against all odds\n",
      "I know we'll be alright this time\n",
      "Darling, just hold my hand\n",
      "Be my girl, I'll be your man\n",
      "I see my future in your eyes\n",
      "Baby, I'\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67862"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Entire Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_characters = set(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = dict(enumerate(all_characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder\n",
    "# decoder.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = {char: ind for ind,char in decoder.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = np.array([encoder[char] for char in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([73, 75,  3, 49, 75,  9, 41, 60,  4, 38, 49, 37, 30, 25, 69, 38, 10,\n",
       "       38, 56, 37, 70, 75, 38, 49, 37,  3, 38, 74, 75, 60, 11, 51, 38, 69,\n",
       "       10,  3, 56, 72, 25, 12, 39, 38, 48, 30, 45, 41, 38, 69, 72, 70, 75,\n",
       "       38,  3, 72, 12, 51, 41, 38, 72, 25, 38, 10, 25, 69, 38, 49, 37, 56,\n",
       "       56, 37, 36, 38, 74,  6, 38, 56, 75, 10, 69, 60, 53, 75, 56, 56, 39,\n",
       "       38,  4, 38, 49, 37, 30, 25, 69, 38, 10, 38, 12, 72,  3, 56, 39, 38,\n",
       "       13, 75, 10, 30, 41, 72, 49, 30, 56, 38, 10, 25, 69, 38, 45, 36, 75,\n",
       "       75, 41, 60, 11, 51, 39, 38,  4, 38, 25, 75, 70, 75,  3, 38, 20, 25,\n",
       "       75, 36, 38,  6, 37, 30, 38, 36, 75,  3, 75, 38, 41, 51, 75, 38, 45,\n",
       "       37, 74, 75, 37, 25, 75, 38, 36, 10, 72, 41, 72, 25, 12, 38, 49, 37,\n",
       "        3, 38, 74, 75, 60, 29,  0, 10, 30, 45, 75, 38, 36, 75, 38, 36, 75,\n",
       "        3, 75, 38, 48, 30, 45, 41, 38, 20, 72, 69, 45, 38, 36, 51, 75, 25,\n",
       "       38, 36, 75, 38, 49, 75, 56, 56, 38, 72, 25, 38, 56, 37, 70, 75, 60,\n",
       "       40, 37, 41, 38, 20, 25, 37, 36, 72, 25, 12, 38, 36, 51, 10, 41, 38,\n",
       "       72, 41, 38, 36, 10, 45, 60,  4, 38, 36, 72, 56, 56, 38, 25, 37, 41,\n",
       "       38, 12, 72, 70, 75, 38,  6, 37, 30, 38, 30,  7, 38, 41, 51, 72, 45,\n",
       "       38, 41, 72, 74, 75, 60, 21, 30, 41, 38, 69, 10,  3, 56, 72, 25, 12,\n",
       "       39, 38, 48, 30, 45, 41, 38, 20, 72, 45, 45, 38, 74, 75, 38, 45, 56,\n",
       "       37, 36, 39, 38,  6, 37, 30,  3, 38, 51, 75, 10,  3, 41, 38, 72, 45,\n",
       "       38, 10, 56, 56, 38,  4, 38, 37, 36, 25, 60, 63, 25, 69, 38, 72, 25,\n",
       "       38,  6, 37, 30,  3, 38, 75,  6, 75, 45, 39, 38,  6, 37, 30, 29,  3,\n",
       "       75, 38, 51, 37, 56, 69, 72, 25, 12, 38, 74, 72, 25, 75, 60, 21, 10,\n",
       "       13,  6, 39, 38,  4, 29, 74, 38, 69, 10, 25,  9, 72, 25, 12, 38, 72,\n",
       "       25, 38, 41, 51, 75, 38, 69, 10,  3, 20, 38, 36, 72, 41, 51, 38,  6,\n",
       "       37, 30, 38, 13, 75, 41, 36, 75, 75, 25, 38, 74,  6, 38, 10,  3, 74,\n",
       "       45, 60, 21, 10,  3, 75, 49, 37, 37, 41, 38, 37, 25, 38, 41, 51, 75,\n",
       "       38, 12,  3, 10, 45, 45, 39, 38, 56, 72, 45, 41, 75, 25, 72, 25, 12,\n",
       "       38, 41, 37, 38, 37, 30,  3, 38, 49, 10, 70, 37, 30,  3, 72, 41, 75,\n",
       "       38, 45, 37, 25, 12, 60, 53, 51, 75, 25, 38,  6, 37, 30, 38, 45, 10,\n",
       "       72, 69, 38,  6, 37, 30, 38])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding\n",
    "\n",
    "As previously discussed, we need to one-hot encode our data inorder for it to work with the network structure. Make sure to review numpy if any of these operations confuse you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(encoded_text, num_uni_chars):\n",
    "    '''\n",
    "    encoded_text : batch of encoded text\n",
    "    \n",
    "    num_uni_chars = number of unique characters (len(set(text)))\n",
    "    '''\n",
    "    \n",
    "    # METHOD FROM:\n",
    "    # https://stackoverflow.com/questions/29831489/convert-encoded_textay-of-indices-to-1-hot-encoded-numpy-encoded_textay\n",
    "      \n",
    "    # Create a placeholder for zeros.\n",
    "    one_hot = np.zeros((encoded_text.size, num_uni_chars))\n",
    "    \n",
    "    # Convert data type for later use with pytorch (errors if we dont!)\n",
    "    one_hot = one_hot.astype(np.float32)\n",
    "\n",
    "    # Using fancy indexing fill in the 1s at the correct index locations\n",
    "    one_hot[np.arange(one_hot.shape[0]), encoded_text.flatten()] = 1.0\n",
    "    \n",
    "\n",
    "    # Reshape it so it matches the batch sahe\n",
    "    one_hot = one_hot.reshape((*encoded_text.shape, num_uni_chars))\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "55014\n",
      "(5, 84)\n"
     ]
    }
   ],
   "source": [
    "a=one_hot_encoder(encoded_text[:5],84)\n",
    "print(a)\n",
    "print(encoded_text.size)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "---------------\n",
    "# Creating Training Batches\n",
    "\n",
    "We need to create a function that will generate batches of characters along with the next character in the sequence as a label.\n",
    "\n",
    "-----------------\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5],\n",
       "       [6, 7],\n",
       "       [8, 9]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we wanted 5 batches\n",
    "example_text.reshape((5,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(encoded_text, samp_per_batch=10, seq_len=50):\n",
    "    \n",
    "    '''\n",
    "    Generate (using yield) batches for training.\n",
    "    \n",
    "    X: Encoded Text of length seq_len\n",
    "    Y: Encoded Text shifted by one\n",
    "    \n",
    "    Example:\n",
    "    \n",
    "    X:\n",
    "    \n",
    "    [[1 2 3]]\n",
    "    \n",
    "    Y:\n",
    "    \n",
    "    [[ 2 3 4]]\n",
    "    \n",
    "    encoded_text : Complete Encoded Text to make batches from\n",
    "    batch_size : Number of samples per batch\n",
    "    seq_len : Length of character sequence\n",
    "       \n",
    "    '''\n",
    "    \n",
    "    # Total number of characters per batch\n",
    "    # Example: If samp_per_batch is 2 and seq_len is 50, then 100\n",
    "    # characters come out per batch.\n",
    "    char_per_batch = samp_per_batch * seq_len\n",
    "    \n",
    "    \n",
    "    # Number of batches available to make\n",
    "    # Use int() to roun to nearest integer\n",
    "    num_batches_avail = int(len(encoded_text)/char_per_batch)\n",
    "    \n",
    "    # Cut off end of encoded_text that\n",
    "    # won't fit evenly into a batch\n",
    "    encoded_text = encoded_text[:num_batches_avail * char_per_batch]\n",
    "    \n",
    "    \n",
    "    # Reshape text into rows the size of a batch\n",
    "    encoded_text = encoded_text.reshape((samp_per_batch, -1))\n",
    "\n",
    "\n",
    "    # Go through each row in array.\n",
    "    for n in range(0, encoded_text.shape[1], seq_len):\n",
    "        \n",
    "        # Grab feature characters\n",
    "        x = encoded_text[:, n:n+seq_len]\n",
    "        \n",
    "        # y is the target shifted over by 1\n",
    "        y = np.zeros_like(x)\n",
    "       \n",
    "        #\n",
    "        try:\n",
    "            y[:, :-1] = x[:, 1:]\n",
    "            y[:, -1]  = encoded_text[:, n+seq_len]\n",
    "            \n",
    "        # FOR POTENTIAL INDEXING ERROR AT THE END    \n",
    "        except:\n",
    "            y[:, :-1] = x[:, 1:]\n",
    "            y[:, -1] = encoded_text[:, 0]\n",
    "            \n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of generating a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = np.arange(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_generator = generate_batches(sample_text,samp_per_batch=2,seq_len=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab first batch\n",
    "x, y = next(batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4],\n",
       "       [10, 11, 12, 13, 14]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5],\n",
       "       [11, 12, 13, 14, 15]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Check\n",
    "\n",
    "Remember this will take a lot longer on CPU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1],\n",
      "        [2, 3]])\n",
      "tensor([[0, 2],\n",
      "        [1, 3]])\n",
      "tensor([[0, 2],\n",
      "        [1, 3]])\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "base = torch.tensor([[0, 1],[2, 3]])\n",
    "t = base.transpose(0, 1)\n",
    "c = t.contiguous()\n",
    "print(base)\n",
    "print(t)\n",
    "print(c)\n",
    "print(t.is_contiguous())\n",
    "print(c.is_contiguous())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the LSTM Model\n",
    "\n",
    "**Note! We will have options for GPU users and CPU users. CPU will take MUCH LONGER to train and you may encounter RAM issues depending on your hardware. If that is the case, consider using cloud services like AWS, GCP, or Azure. Note, these may cost you money to use!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, all_chars, num_hidden=256, num_layers=4,drop_prob=0.5,use_gpu=False):\n",
    "        \n",
    "        \n",
    "        # SET UP ATTRIBUTES\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.num_layers = num_layers\n",
    "        self.num_hidden = num_hidden\n",
    "        self.use_gpu = use_gpu\n",
    "        \n",
    "        #CHARACTER SET, ENCODER, and DECODER\n",
    "        self.all_chars = all_chars\n",
    "        self.decoder = dict(enumerate(all_chars))\n",
    "        self.encoder = {char: ind for ind,char in self.decoder.items()}\n",
    "        \n",
    "        \n",
    "        self.lstm = nn.LSTM(len(self.all_chars), num_hidden, num_layers, dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        self.fc_linear = nn.Linear(num_hidden, len(self.all_chars))\n",
    "      \n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "                  \n",
    "        \n",
    "        lstm_output, hidden = self.lstm(x, hidden)\n",
    "        \n",
    "        \n",
    "        drop_output = self.dropout(lstm_output)\n",
    "        \n",
    "        drop_output = drop_output.contiguous().view(-1, self.num_hidden)\n",
    "        \n",
    "        \n",
    "        final_out = self.fc_linear(drop_output)\n",
    "        return final_out, hidden\n",
    "    \n",
    "    \n",
    "    def hidden_state(self, batch_size):\n",
    "        '''\n",
    "        Used as separate method to account for both GPU and CPU users.\n",
    "        '''\n",
    "        \n",
    "        if self.use_gpu:\n",
    "            \n",
    "            hidden = (torch.zeros(self.num_layers,batch_size,self.num_hidden).cuda(),\n",
    "                     torch.zeros(self.num_layers,batch_size,self.num_hidden).cuda())\n",
    "        else:\n",
    "            hidden = (torch.zeros(self.num_layers,batch_size,self.num_hidden),\n",
    "                     torch.zeros(self.num_layers,batch_size,self.num_hidden))\n",
    "        \n",
    "        return hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharModel(\n",
    "    all_chars=all_characters,\n",
    "    num_hidden=50,\n",
    "    num_layers=2,\n",
    "    drop_prob=0.5,\n",
    "    use_gpu=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_param  = []\n",
    "for p in model.parameters():\n",
    "    total_param.append(int(p.numel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to make the total_parameters be roughly the same magnitude as the number of characters in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49876"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(total_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55014"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of data to be used for training\n",
    "train_percent = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55014"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38509"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(encoded_text) * (train_percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ind = int(len(encoded_text) * (train_percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = encoded_text[:train_ind]\n",
    "val_data = encoded_text[train_ind:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "\n",
    "Feel free to play around with these values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VARIABLES\n",
    "\n",
    "# Epochs to train for\n",
    "epochs = 1000\n",
    "# batch size \n",
    "batch_size = 100\n",
    "\n",
    "# Length of sequence\n",
    "seq_len = 30\n",
    "\n",
    "# for printing report purposes\n",
    "# always start at 0\n",
    "tracker = 0\n",
    "c=0\n",
    "# number of characters in text\n",
    "num_char = max(encoded_text)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "Epoch: 1 Step: 25 Val Loss: 2.337758779525757\n",
      "0\n",
      "Epoch: 3 Step: 50 Val Loss: 2.3268332481384277\n",
      "2\n",
      "Epoch: 4 Step: 75 Val Loss: 2.3207383155822754\n",
      "3\n",
      "Epoch: 6 Step: 100 Val Loss: 2.31697678565979\n",
      "5\n",
      "Epoch: 8 Step: 125 Val Loss: 2.3142123222351074\n",
      "7\n",
      "Epoch: 9 Step: 150 Val Loss: 2.3120944499969482\n",
      "8\n",
      "Epoch: 11 Step: 175 Val Loss: 2.3102731704711914\n",
      "10\n",
      "Epoch: 13 Step: 200 Val Loss: 2.308400869369507\n",
      "12\n",
      "Epoch: 14 Step: 225 Val Loss: 2.306952714920044\n",
      "13\n",
      "Epoch: 16 Step: 250 Val Loss: 2.305413007736206\n",
      "15\n",
      "Epoch: 18 Step: 275 Val Loss: 2.3035504817962646\n",
      "17\n",
      "Epoch: 19 Step: 300 Val Loss: 2.3018245697021484\n",
      "18\n",
      "Epoch: 21 Step: 325 Val Loss: 2.3001110553741455\n",
      "20\n",
      "Epoch: 23 Step: 350 Val Loss: 2.2986505031585693\n",
      "22\n",
      "Epoch: 24 Step: 375 Val Loss: 2.2974255084991455\n",
      "23\n",
      "Epoch: 26 Step: 400 Val Loss: 2.2964632511138916\n",
      "25\n",
      "Epoch: 28 Step: 425 Val Loss: 2.294365644454956\n",
      "27\n",
      "Epoch: 29 Step: 450 Val Loss: 2.2924606800079346\n",
      "28\n",
      "Epoch: 31 Step: 475 Val Loss: 2.291015386581421\n",
      "30\n",
      "Epoch: 33 Step: 500 Val Loss: 2.2899162769317627\n",
      "32\n",
      "Epoch: 34 Step: 525 Val Loss: 2.2885499000549316\n",
      "33\n",
      "Epoch: 36 Step: 550 Val Loss: 2.287458896636963\n",
      "35\n",
      "Epoch: 38 Step: 575 Val Loss: 2.2862541675567627\n",
      "37\n",
      "Epoch: 39 Step: 600 Val Loss: 2.2840113639831543\n",
      "38\n",
      "Epoch: 41 Step: 625 Val Loss: 2.2826507091522217\n",
      "40\n",
      "Epoch: 43 Step: 650 Val Loss: 2.2813379764556885\n",
      "42\n",
      "Epoch: 44 Step: 675 Val Loss: 2.27948260307312\n",
      "43\n",
      "Epoch: 46 Step: 700 Val Loss: 2.2783379554748535\n",
      "45\n",
      "Epoch: 48 Step: 725 Val Loss: 2.2763848304748535\n",
      "47\n",
      "Epoch: 49 Step: 750 Val Loss: 2.2749416828155518\n",
      "48\n",
      "Epoch: 51 Step: 775 Val Loss: 2.2729952335357666\n",
      "50\n",
      "Epoch: 53 Step: 800 Val Loss: 2.2714593410491943\n",
      "52\n",
      "Epoch: 54 Step: 825 Val Loss: 2.2701876163482666\n",
      "53\n",
      "Epoch: 56 Step: 850 Val Loss: 2.2686877250671387\n",
      "55\n",
      "Epoch: 58 Step: 875 Val Loss: 2.2669742107391357\n",
      "57\n",
      "Epoch: 59 Step: 900 Val Loss: 2.2652032375335693\n",
      "58\n",
      "Epoch: 61 Step: 925 Val Loss: 2.264122247695923\n",
      "60\n",
      "Epoch: 63 Step: 950 Val Loss: 2.2627601623535156\n",
      "62\n",
      "Epoch: 64 Step: 975 Val Loss: 2.2609081268310547\n",
      "63\n",
      "Epoch: 66 Step: 1000 Val Loss: 2.259674072265625\n",
      "65\n",
      "Epoch: 68 Step: 1025 Val Loss: 2.2573940753936768\n",
      "67\n",
      "Epoch: 69 Step: 1050 Val Loss: 2.2565295696258545\n",
      "68\n",
      "Epoch: 71 Step: 1075 Val Loss: 2.2545840740203857\n",
      "70\n",
      "Epoch: 73 Step: 1100 Val Loss: 2.2533020973205566\n",
      "72\n",
      "Epoch: 74 Step: 1125 Val Loss: 2.251530170440674\n",
      "73\n",
      "Epoch: 76 Step: 1150 Val Loss: 2.2499847412109375\n",
      "75\n",
      "Epoch: 78 Step: 1175 Val Loss: 2.2478809356689453\n",
      "77\n",
      "Epoch: 79 Step: 1200 Val Loss: 2.246594190597534\n",
      "78\n",
      "Epoch: 81 Step: 1225 Val Loss: 2.245123863220215\n",
      "80\n",
      "Epoch: 83 Step: 1250 Val Loss: 2.2433433532714844\n",
      "82\n",
      "Epoch: 84 Step: 1275 Val Loss: 2.2408928871154785\n",
      "83\n",
      "Epoch: 86 Step: 1300 Val Loss: 2.2399048805236816\n",
      "85\n",
      "Epoch: 88 Step: 1325 Val Loss: 2.2379958629608154\n",
      "87\n",
      "Epoch: 89 Step: 1350 Val Loss: 2.2362422943115234\n",
      "88\n",
      "Epoch: 91 Step: 1375 Val Loss: 2.2345547676086426\n",
      "90\n",
      "Epoch: 93 Step: 1400 Val Loss: 2.232891321182251\n",
      "92\n",
      "Epoch: 94 Step: 1425 Val Loss: 2.23126220703125\n",
      "93\n",
      "Epoch: 96 Step: 1450 Val Loss: 2.229429244995117\n",
      "95\n",
      "Epoch: 98 Step: 1475 Val Loss: 2.228213310241699\n",
      "97\n",
      "Epoch: 99 Step: 1500 Val Loss: 2.2256524562835693\n",
      "98\n",
      "Epoch: 101 Step: 1525 Val Loss: 2.2234432697296143\n",
      "100\n",
      "Epoch: 103 Step: 1550 Val Loss: 2.2210278511047363\n",
      "102\n",
      "Epoch: 104 Step: 1575 Val Loss: 2.220078229904175\n",
      "103\n",
      "Epoch: 106 Step: 1600 Val Loss: 2.2173080444335938\n",
      "105\n",
      "Epoch: 108 Step: 1625 Val Loss: 2.217039108276367\n",
      "107\n",
      "Epoch: 109 Step: 1650 Val Loss: 2.2140748500823975\n",
      "108\n",
      "Epoch: 111 Step: 1675 Val Loss: 2.2117090225219727\n",
      "110\n",
      "Epoch: 113 Step: 1700 Val Loss: 2.210418224334717\n",
      "112\n",
      "Epoch: 114 Step: 1725 Val Loss: 2.209533214569092\n",
      "113\n",
      "Epoch: 116 Step: 1750 Val Loss: 2.207111120223999\n",
      "115\n",
      "Epoch: 118 Step: 1775 Val Loss: 2.2056615352630615\n",
      "117\n",
      "Epoch: 119 Step: 1800 Val Loss: 2.203181743621826\n",
      "118\n",
      "Epoch: 121 Step: 1825 Val Loss: 2.2010550498962402\n",
      "120\n",
      "Epoch: 123 Step: 1850 Val Loss: 2.198514699935913\n",
      "122\n",
      "Epoch: 124 Step: 1875 Val Loss: 2.1970431804656982\n",
      "123\n",
      "Epoch: 126 Step: 1900 Val Loss: 2.1954433917999268\n",
      "125\n",
      "Epoch: 128 Step: 1925 Val Loss: 2.194474220275879\n",
      "127\n",
      "Epoch: 129 Step: 1950 Val Loss: 2.193267345428467\n",
      "128\n",
      "Epoch: 131 Step: 1975 Val Loss: 2.1908950805664062\n",
      "130\n",
      "Epoch: 133 Step: 2000 Val Loss: 2.187201976776123\n",
      "132\n",
      "Epoch: 134 Step: 2025 Val Loss: 2.1864912509918213\n",
      "133\n",
      "Epoch: 136 Step: 2050 Val Loss: 2.184028148651123\n",
      "135\n",
      "Epoch: 138 Step: 2075 Val Loss: 2.1816532611846924\n",
      "137\n",
      "Epoch: 139 Step: 2100 Val Loss: 2.181008815765381\n",
      "138\n",
      "Epoch: 141 Step: 2125 Val Loss: 2.180140256881714\n",
      "140\n",
      "Epoch: 143 Step: 2150 Val Loss: 2.1760895252227783\n",
      "142\n",
      "Epoch: 144 Step: 2175 Val Loss: 2.1769731044769287\n",
      "143\n",
      "Epoch: 146 Step: 2200 Val Loss: 2.1735687255859375\n",
      "145\n",
      "Epoch: 148 Step: 2225 Val Loss: 2.17010498046875\n",
      "147\n",
      "Epoch: 149 Step: 2250 Val Loss: 2.170588970184326\n",
      "148\n",
      "Epoch: 151 Step: 2275 Val Loss: 2.169013500213623\n",
      "150\n",
      "Epoch: 153 Step: 2300 Val Loss: 2.1662771701812744\n",
      "152\n",
      "Epoch: 154 Step: 2325 Val Loss: 2.1641268730163574\n",
      "153\n",
      "Epoch: 156 Step: 2350 Val Loss: 2.1634790897369385\n",
      "155\n",
      "Epoch: 158 Step: 2375 Val Loss: 2.1623291969299316\n",
      "157\n",
      "Epoch: 159 Step: 2400 Val Loss: 2.159921169281006\n",
      "158\n",
      "Epoch: 161 Step: 2425 Val Loss: 2.157686948776245\n",
      "160\n",
      "Epoch: 163 Step: 2450 Val Loss: 2.1575591564178467\n",
      "162\n",
      "Epoch: 164 Step: 2475 Val Loss: 2.155595541000366\n",
      "163\n",
      "Epoch: 166 Step: 2500 Val Loss: 2.15463924407959\n",
      "165\n",
      "Epoch: 168 Step: 2525 Val Loss: 2.1509499549865723\n",
      "167\n",
      "Epoch: 169 Step: 2550 Val Loss: 2.1533470153808594\n",
      "168\n",
      "Epoch: 171 Step: 2575 Val Loss: 2.1498961448669434\n",
      "170\n",
      "Epoch: 173 Step: 2600 Val Loss: 2.147286891937256\n",
      "172\n",
      "Epoch: 174 Step: 2625 Val Loss: 2.1457271575927734\n",
      "173\n",
      "Epoch: 176 Step: 2650 Val Loss: 2.1444201469421387\n",
      "175\n",
      "Epoch: 178 Step: 2675 Val Loss: 2.13993239402771\n",
      "177\n",
      "Epoch: 179 Step: 2700 Val Loss: 2.1424098014831543\n",
      "178\n",
      "Epoch: 181 Step: 2725 Val Loss: 2.1405723094940186\n",
      "180\n",
      "Epoch: 183 Step: 2750 Val Loss: 2.134230375289917\n",
      "182\n",
      "Epoch: 184 Step: 2775 Val Loss: 2.137547254562378\n",
      "183\n",
      "Epoch: 186 Step: 2800 Val Loss: 2.1345765590667725\n",
      "185\n",
      "Epoch: 188 Step: 2825 Val Loss: 2.1279454231262207\n",
      "187\n",
      "Epoch: 189 Step: 2850 Val Loss: 2.1308958530426025\n",
      "188\n",
      "Epoch: 191 Step: 2875 Val Loss: 2.129577159881592\n",
      "190\n",
      "Epoch: 193 Step: 2900 Val Loss: 2.1239237785339355\n",
      "192\n",
      "Epoch: 194 Step: 2925 Val Loss: 2.1282572746276855\n",
      "193\n",
      "Epoch: 196 Step: 2950 Val Loss: 2.1264290809631348\n",
      "195\n",
      "Epoch: 198 Step: 2975 Val Loss: 2.123361587524414\n",
      "197\n",
      "Epoch: 199 Step: 3000 Val Loss: 2.1249141693115234\n",
      "198\n",
      "Epoch: 201 Step: 3025 Val Loss: 2.121882438659668\n",
      "200\n",
      "Epoch: 203 Step: 3050 Val Loss: 2.1222715377807617\n",
      "202\n",
      "Epoch: 204 Step: 3075 Val Loss: 2.12186598777771\n",
      "203\n",
      "Epoch: 206 Step: 3100 Val Loss: 2.12201189994812\n",
      "205\n",
      "Epoch: 208 Step: 3125 Val Loss: 2.1165199279785156\n",
      "207\n",
      "Epoch: 209 Step: 3150 Val Loss: 2.1201090812683105\n",
      "208\n",
      "Epoch: 211 Step: 3175 Val Loss: 2.115630626678467\n",
      "210\n",
      "Epoch: 213 Step: 3200 Val Loss: 2.1121692657470703\n",
      "212\n",
      "Epoch: 214 Step: 3225 Val Loss: 2.117652177810669\n",
      "213\n",
      "Epoch: 216 Step: 3250 Val Loss: 2.113553762435913\n",
      "215\n",
      "Epoch: 218 Step: 3275 Val Loss: 2.108785390853882\n",
      "217\n",
      "Epoch: 219 Step: 3300 Val Loss: 2.1131396293640137\n",
      "218\n",
      "Epoch: 221 Step: 3325 Val Loss: 2.115694761276245\n",
      "220\n",
      "Epoch: 223 Step: 3350 Val Loss: 2.1070635318756104\n",
      "222\n",
      "Epoch: 224 Step: 3375 Val Loss: 2.1080141067504883\n",
      "223\n",
      "Epoch: 226 Step: 3400 Val Loss: 2.1106855869293213\n",
      "225\n",
      "Epoch: 228 Step: 3425 Val Loss: 2.0983221530914307\n",
      "227\n",
      "Epoch: 229 Step: 3450 Val Loss: 2.11470890045166\n",
      "228\n",
      "Epoch: 231 Step: 3475 Val Loss: 2.1022140979766846\n",
      "230\n",
      "Epoch: 233 Step: 3500 Val Loss: 2.0966379642486572\n",
      "232\n",
      "Epoch: 234 Step: 3525 Val Loss: 2.1005444526672363\n",
      "233\n",
      "Epoch: 236 Step: 3550 Val Loss: 2.108416795730591\n",
      "235\n",
      "Epoch: 238 Step: 3575 Val Loss: 2.1030173301696777\n",
      "237\n",
      "Epoch: 239 Step: 3600 Val Loss: 2.0977532863616943\n",
      "238\n",
      "Epoch: 241 Step: 3625 Val Loss: 2.111090898513794\n",
      "240\n",
      "Epoch: 243 Step: 3650 Val Loss: 2.0985753536224365\n",
      "242\n",
      "Epoch: 244 Step: 3675 Val Loss: 2.1116602420806885\n",
      "243\n",
      "Epoch: 246 Step: 3700 Val Loss: 2.09976863861084\n",
      "245\n",
      "Epoch: 248 Step: 3725 Val Loss: 2.0975284576416016\n",
      "247\n",
      "Epoch: 249 Step: 3750 Val Loss: 2.102059841156006\n",
      "248\n",
      "Epoch: 251 Step: 3775 Val Loss: 2.0945510864257812\n",
      "250\n",
      "Epoch: 253 Step: 3800 Val Loss: 2.0961480140686035\n",
      "252\n",
      "Epoch: 254 Step: 3825 Val Loss: 2.099289655685425\n",
      "253\n",
      "Epoch: 256 Step: 3850 Val Loss: 2.1069440841674805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "Epoch: 258 Step: 3875 Val Loss: 2.0942134857177734\n",
      "257\n",
      "Epoch: 259 Step: 3900 Val Loss: 2.094684362411499\n",
      "258\n",
      "Epoch: 261 Step: 3925 Val Loss: 2.0980706214904785\n",
      "260\n",
      "Epoch: 263 Step: 3950 Val Loss: 2.0896027088165283\n",
      "262\n",
      "Epoch: 264 Step: 3975 Val Loss: 2.105560064315796\n",
      "263\n",
      "Epoch: 266 Step: 4000 Val Loss: 2.1005451679229736\n",
      "265\n",
      "Epoch: 268 Step: 4025 Val Loss: 2.0917043685913086\n",
      "267\n",
      "Epoch: 269 Step: 4050 Val Loss: 2.106236457824707\n",
      "268\n",
      "Epoch: 271 Step: 4075 Val Loss: 2.1033496856689453\n",
      "270\n",
      "Epoch: 273 Step: 4100 Val Loss: 2.0909159183502197\n",
      "272\n",
      "Epoch: 274 Step: 4125 Val Loss: 2.1012909412384033\n",
      "273\n",
      "Epoch: 276 Step: 4150 Val Loss: 2.0977938175201416\n",
      "275\n",
      "Epoch: 278 Step: 4175 Val Loss: 2.0881261825561523\n",
      "277\n",
      "Epoch: 279 Step: 4200 Val Loss: 2.098073959350586\n",
      "278\n",
      "Epoch: 281 Step: 4225 Val Loss: 2.1000113487243652\n",
      "280\n",
      "Epoch: 283 Step: 4250 Val Loss: 2.093205690383911\n",
      "282\n",
      "Epoch: 284 Step: 4275 Val Loss: 2.0970420837402344\n",
      "283\n",
      "Epoch: 286 Step: 4300 Val Loss: 2.1031954288482666\n",
      "285\n",
      "Epoch: 288 Step: 4325 Val Loss: 2.0933070182800293\n",
      "287\n",
      "Epoch: 289 Step: 4350 Val Loss: 2.104309320449829\n",
      "288\n",
      "Epoch: 291 Step: 4375 Val Loss: 2.1035501956939697\n"
     ]
    }
   ],
   "source": [
    "# Set model to train\n",
    "model.train()\n",
    "\n",
    "\n",
    "# Check to see if using GPU\n",
    "if model.use_gpu:\n",
    "    model.cuda()\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    hidden = model.hidden_state(batch_size)\n",
    "    \n",
    "    \n",
    "    for x,y in generate_batches(train_data,batch_size,seq_len):\n",
    "        \n",
    "        tracker += 1\n",
    "        \n",
    "        # One Hot Encode incoming data\n",
    "        x = one_hot_encoder(x,num_char)\n",
    "        \n",
    "        # Convert Numpy Arrays to Tensor\n",
    "        \n",
    "        inputs = torch.from_numpy(x)\n",
    "        targets = torch.from_numpy(y)\n",
    "        \n",
    "        # Adjust for GPU if necessary\n",
    "        \n",
    "        if model.use_gpu:\n",
    "            \n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            \n",
    "        # Reset Hidden State\n",
    "        # If we dont' reset we would backpropagate through all training history\n",
    "        hidden = tuple([state.data for state in hidden])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        lstm_output, hidden = model.forward(inputs,hidden)\n",
    "        \n",
    "        loss = criterion(lstm_output,targets.view(batch_size*seq_len).long())\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # POSSIBLE EXPLODING GRADIENT PROBLEM!\n",
    "        # LET\"S CLIP JUST IN CASE\n",
    "        nn.utils.clip_grad_norm_(model.parameters(),max_norm=5)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        ###################################\n",
    "        ### CHECK ON VALIDATION SET ######\n",
    "        #################################\n",
    "        \n",
    "        if tracker % 25 == 0:\n",
    "            \n",
    "            val_hidden = model.hidden_state(batch_size)\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "            \n",
    "            for x,y in generate_batches(val_data,batch_size,seq_len):\n",
    "                \n",
    "                # One Hot Encode incoming data\n",
    "                x = one_hot_encoder(x,num_char)\n",
    "                \n",
    "\n",
    "                # Convert Numpy Arrays to Tensor\n",
    "\n",
    "                inputs = torch.from_numpy(x)\n",
    "                targets = torch.from_numpy(y)\n",
    "\n",
    "                # Adjust for GPU if necessary\n",
    "\n",
    "                if model.use_gpu:\n",
    "\n",
    "                    inputs = inputs.cuda()\n",
    "                    targets = targets.cuda()\n",
    "                    \n",
    "                # Reset Hidden State\n",
    "                # If we dont' reset we would backpropagate through \n",
    "                # all training history\n",
    "                val_hidden = tuple([state.data for state in val_hidden])\n",
    "                \n",
    "                lstm_output, val_hidden = model.forward(inputs,val_hidden)\n",
    "                val_loss = criterion(lstm_output,targets.view(batch_size*seq_len).long())\n",
    "        \n",
    "                val_losses.append(val_loss.item())\n",
    "            \n",
    "            # Reset to training model after val for loop\n",
    "            model.train()\n",
    "            if abs(val_loss.item()-c)<0.1 or val_loss.item()>c:\n",
    "                print(epochs)\n",
    "                epochs=i-1\n",
    "            print(f\"Epoch: {i} Step: {tracker} Val Loss: {val_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 30])\n"
     ]
    }
   ],
   "source": [
    "a1=targets.view(batch_size*seq_len)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "------\n",
    "\n",
    "## Saving the Model\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/saving_loading_models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful to overwrite our original name file!\n",
    "model_name = 'example3.net'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUST MATCH THE EXACT SAME SETTINGS AS MODEL USED DURING TRAINING!\n",
    "\n",
    "model = CharModel(\n",
    "    all_chars=all_characters,\n",
    "    num_hidden=50,\n",
    "    num_layers=2,\n",
    "    drop_prob=0.5,\n",
    "    use_gpu=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharModel(\n",
       "  (lstm): LSTM(76, 50, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (fc_linear): Linear(in_features=50, out_features=76, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_name))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_char(model, char, hidden=None, k=1):\n",
    "        \n",
    "        # Encode raw letters with model\n",
    "        encoded_text = model.encoder[char]\n",
    "        \n",
    "        # set as numpy array for one hot encoding\n",
    "        # NOTE THE [[ ]] dimensions!!\n",
    "        encoded_text = np.array([[encoded_text]])\n",
    "        \n",
    "        # One hot encoding\n",
    "        encoded_text = one_hot_encoder(encoded_text, len(model.all_chars))\n",
    "        \n",
    "        # Convert to Tensor\n",
    "        inputs = torch.from_numpy(encoded_text)\n",
    "        \n",
    "        # Check for CPU\n",
    "        if(model.use_gpu):\n",
    "            inputs = inputs.cuda()\n",
    "        \n",
    "        \n",
    "        # Grab hidden states\n",
    "        hidden = tuple([state.data for state in hidden])\n",
    "        \n",
    "        \n",
    "        # Run model and get predicted output\n",
    "        lstm_out, hidden = model(inputs, hidden)\n",
    "\n",
    "        \n",
    "        # Convert lstm_out to probabilities\n",
    "        probs = F.softmax(lstm_out, dim=1).data\n",
    "        \n",
    "        \n",
    "        \n",
    "        if(model.use_gpu):\n",
    "            # move back to CPU to use with numpy\n",
    "            probs = probs.cpu()\n",
    "        \n",
    "        \n",
    "        # k determines how many characters to consider\n",
    "        # for our probability choice.\n",
    "        # https://pytorch.org/docs/stable/torch.html#torch.topk\n",
    "        \n",
    "        # Return k largest probabilities in tensor\n",
    "        probs, index_positions = probs.topk(k)\n",
    "        \n",
    "        \n",
    "        index_positions = index_positions.numpy().squeeze()\n",
    "        \n",
    "        # Create array of probabilities\n",
    "        probs = probs.numpy().flatten()\n",
    "        \n",
    "        # Convert to probabilities per index\n",
    "        probs = probs/probs.sum()\n",
    "        \n",
    "        # randomly choose a character based on probabilities\n",
    "        char = np.random.choice(index_positions, p=probs)\n",
    "       \n",
    "        # return the encoded value of the predicted char and the hidden state\n",
    "        return model.decoder[char], hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, size, seed='The', k=1):\n",
    "        \n",
    "      \n",
    "    \n",
    "    # CHECK FOR GPU\n",
    "    if(model.use_gpu):\n",
    "        model.cuda()\n",
    "    else:\n",
    "        model.cpu()\n",
    "    \n",
    "    # Evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # begin output from initial seed\n",
    "    output_chars = [c for c in seed]\n",
    "    \n",
    "    # intiate hidden state\n",
    "    hidden = model.hidden_state(1)\n",
    "    \n",
    "    # predict the next character for every character in seed\n",
    "    for char in seed:\n",
    "        char, hidden = predict_next_char(model, char, hidden, k=k)\n",
    "    \n",
    "    # add initial characters to output\n",
    "    output_chars.append(char)\n",
    "    \n",
    "    # Now generate for size requested\n",
    "    for i in range(size):\n",
    "        \n",
    "        # predict based off very last letter in output_chars\n",
    "        char, hidden = predict_next_char(model, output_chars[-1], hidden, k=k)\n",
    "        \n",
    "        # add predicted character\n",
    "        output_chars.append(char)\n",
    "    \n",
    "    # return string of predicted text\n",
    "    return ''.join(output_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The the seas sin the sorin that\n",
      "I to soud sounge sit the the tor mand the\n",
      "She to me sease\n",
      "And the\n",
      "So see sout see the the soud see me till sor there thing\n",
      "And mare\n",
      "Ang that sat to me tilt sare thing\n",
      "And\n",
      "Ang sond me\n",
      "So the\n",
      "Shis\n",
      "And sore\n",
      "Ang son sor the me thing tores\n",
      "And than to see son me\n",
      "Ald son\n",
      "Sa the me san the the to sor ther\n",
      "I tin me\n",
      "I me than\n",
      "I me me son me me sat tith site see sout the sis meris seithe\n",
      "I the son sore to thit the\n",
      "And to me the thin seere the site son\n",
      "I't tor to tind,\n",
      "I soung me\n",
      "I me\n",
      "I's\n",
      "And sand the the sin sithe mere sithe mere\n",
      "So son\n",
      "Ang tor tilt me seand me\n",
      "I to to sores\n",
      "Are san sin found man that the\n",
      "And sin she\n",
      "I tor soud tint sease an sean the mite me the ting the mat seen\n",
      "I me soud man me\n",
      "And\n",
      "So sare to tith me to sise mint the\n",
      "She mathe singis soungin lere tore\n",
      "I't the sees the to son\n",
      "Sher thit me to to mith the soungith sor me\n",
      "And son\n",
      "So me mind sore\n",
      "I the san\n",
      "I site the me to to there\n",
      "Ande\n",
      "Are me the see the man thare\n",
      "All the to mere\n",
      "I sare\n",
      "I't soute\n",
      "All to \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, 1000, seed='The ', k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
